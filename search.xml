<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[随笔05/08/20]]></title>
    <url>%2F2020%2F05%2F08%2F%E9%9A%8F%E7%AC%9405-08-20%2F</url>
    <content type="text"><![CDATA[已经五月过几天了.前两天才过完自己22岁(虽然自己身份证上也才21岁 哈哈哈). 一直决定以来的考研也面临着被课程时间所占用时间.感觉自己时间虽然不算特别满满当当但也不太想挤出时间去复习(也就是那种知道自己不能这样但又不想改变就只能这样). 内心的想法一直在动摇 一直在思考着以后能不能考上研(照理说按现在这样去复习注定是考不上的 哎) 记录下此时的心境吧 不过还是希望能够赶紧完成课程作业然后专心踏实的复习考研~~]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase集群配置搭建]]></title>
    <url>%2F2020%2F05%2F08%2FHBase%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1.集群分配这里搭建一个 3 节点的 HBase 集群，其中三台主机上均为 Regin Server。同时为了保证高可用，除了在 master 上部署主 Master 服务外，还在 slave1 上部署备用的 Master 服务。Master 服务由 Zookeeper 集群进行协调管理，如果主 Master 不可用，则备用 Master 会成为新的主 Master。 2.前置条件HBase 的运行需要依赖 Hadoop 和 JDK(HBase 2.0+ 对应 JDK 1.8+) 。同时为了保证高可用，这里我们不采用 HBase 内置的 Zookeeper 服务，而采用外置的 Zookeeper 集群。相关搭建步骤可以参阅 3.集群搭建3.1 下载并解压讲下载好的HBase可以通过WinScp上传到服务器上.然后进行解压: 1# tar -zxvf hbase-1.2.0-cdh5.15.2.tar.gz 3.2 配置环境变量1# vim /etc/profile 添加环境变量: 12export HBASE_HOME=usr/app/hbase-1.2.0-cdh5.15.2export PATH=$HBASE_HOME/bin:$PATH 使得配置生效: 12export HBASE_HOME=usr/app/hbase-1.2.0-cdh5.15.2export PATH=$HBASE_HOME/bin:$PATH 3.3 集群配置进入${HBASE_HOME}/conf目录下,修改配置: hbase-env.sh 1234# 配置JDK安装位置export JAVA_HOME=/usr/java/jdk1.8.0_231# 不使用内置的zookeeper服务export HBASE_MANAGES_ZK=false hbase-site.xml 1234567891011121314151617&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定 hbase 以分布式集群的方式运行 --&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定 hbase 在 HDFS 上的存储位置 --&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://hadoop001:8020/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定 zookeeper 的地址--&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hadoop001:2181,hadoop002:2181,hadoop003:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; regionservers 123masterslave1slave2 backup-masters 1slave1 注:backup-masters 这个文件是不存在的，需要新建，主要用来指明备用的 master 节点，可以是多个，这里我们以 1 个为例。 3.4 安装包分发将 HBase 的安装包分发到其他服务器，分发后建议在这两台服务器上也配置一下 HBase 的环境变量。 12scp -r /usr/local/hbase-2.0.0/ slave1:usr/local/scp -r /usr/local/hbase-2.0.0/ slave2:usr/local/ 4 启动集群4.1 启动ZooKeeper集群分别到三台服务器上启动 ZooKeeper 服务： 1zkServer.sh start 4.2 启动Hadoop集群1234# 启动dfs服务start-dfs.sh# 启动yarn服务start-yarn.sh 4.3 启动HBase集群进入 master 的 ${HBASE_HOME}/bin，使用以下命令启动 HBase 集群。执行此命令后，会在 master 上启动 Master 服务，在 slave1 上启动备用 Master 服务，在 regionservers 文件中配置的所有节点启动 region server 服务。 1start-hbase.sh 4.4 查看服务访问 HBase 的 Web-UI 界面，这里我安装的 HBase 版本为 2.0.0，访问端口为 16010，如果你安装的是 2.0 以下的版本，则访问端口号为 60010。可以看到 Master 在 master 上，三个 Regin Servers 分别在 master，slave1，和 slave2 上，并且还有一个 Backup Matser 服务在 slave1 上。 结束至此,已经在三台虚拟机上将Hadoop2.8.5,Zookeeper3.4.14以及Hbase2.0.0搭建全部结束]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群配置搭建]]></title>
    <url>%2F2020%2F05%2F08%2FZookeeper%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1.Zookeeper集群环境搭建1.1下载下载对应版本 Zookeeper，这里我下载的版本 3.4.14。官方下载地址：https://archive.apache.org/dist/zookeeper/ 1# wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz 1.2解压1# tar -zxvf zookeeper-3.4.14.tar.gz 1.3配置环境解压1# vim /etc/profile 添加环境变量: 12export ZOOKEEPER_HOME=/usr/app/zookeeper-3.4.14export PATH=$ZOOKEEPER_HOME/bin:$PATH 使得配置生效: 1# source /etc/profile 1.4修改配置进入安装目录的 conf/ 目录下，拷贝配置样本并进行修改： 1# cp zoo_sample.cfg zoo.cfg 指定数据存储目录和日志文件目录（目录不用预先创建，程序会自动创建），修改后完整配置如下： 123456789101112tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper-cluster/data/dataLogDir=/usr/local/zookeeper-cluster/log/clientPort=2181# server.1 这个1是服务器的标识，可以是任意有效数字，标识这是第几个服务器节点，这个标识要写到dataDir目录下面myid文件里# 指名集群间通讯端口和选举端口server.1=master:2287:3387server.2=slave1:2287:3387server.3=slave2:2287:3387 配置说明: tickTime：用于计算的基础时间单元。比如 session 超时：N*tickTime； initLimit：用于集群，允许从节点连接并同步到 master 节点的初始化连接时间，以 tickTime 的倍数来表示； syncLimit：用于集群， master 主节点与从节点之间发送消息，请求和应答时间长度（心跳机制）； dataDir：数据存储位置； dataLogDir：日志目录； clientPort：用于客户端连接的端口，默认 2181 1.5 标识节点分别在三台主机的 dataDir 目录下新建 myid 文件,并写入对应的节点标识。Zookeeper 集群通过 myid 文件识别集群节点，并通过上文配置的节点通信端口和选举端口来进行节点通信，选举出 Leader 节点。创建存储目录： 12# 三台主机均执行该命令mkdir -vp /usr/local/zookeeper-cluster/data/ 创建并写入节点标识到 myid 文件： 123456# master主机echo &quot;1&quot; &gt; /usr/local/zookeeper-cluster/data/myid# slave1主机echo &quot;2&quot; &gt; /usr/local/zookeeper-cluster/data/myid# slave2主机echo &quot;3&quot; &gt; /usr/local/zookeeper-cluster/data/myid 1.5 启动分别在三台主机运行以下命令 1zkServer.sh start 1.6 验证启动后使用 zkServer.sh status 查看集群各个节点状态。]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop集群搭建]]></title>
    <url>%2F2020%2F05%2F08%2Fhadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1. 基本环境1.1 三台虚拟机169.254.110.100 master 169.254.110.101 slave1 169.254.110.102 slave2 1.2 软件包jdk-8u231-linux-i586.tar.gz hadoop-2.8.5.tar.gz 2. 环境配置2.1 新建hadoop用户useradd hadoop 通过passwd命令修改hadoop用户密码，启用hadoop用户。passwd hadoop 2.2 配置ssh免密码登录2.2.1 集群环境 节点名称 节点ip master 169.254.110.100 slave1 169.254.110.101 slave2 169.254.110.102 2.2.2 免登录原理每台主机authorized_keys文件里面包含的主机（ssh密钥），该主机都能无密码登录，所以只要每台主机的authorized_keys文件里面都放入其他主机（需要无密码登录的主机）的ssh密钥就行了。 2.2.3 实现每个节点生成ssh密钥 123456789101112[root@master ~]# ssh-keygen -t rsa(一直点确定)Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Created directory &apos;/root/.ssh&apos;.Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub......................[root@master .ssh]# lsid_rsa id_rsa.pub 在主节点(master)将公钥(id_rsa.pub)拷到一个特定文件authorized_keys中 123[root@master .ssh]# cp id_rsa.pub authorized_keys[root@master .ssh]# lsauthorized_keys id_rsa id_rsa.pub 然后将该文件拷到下一个节点中去,并将该节点的ssh密钥追加到该文件中 123456789101112131415#在master上使用scp命令实现远程文件拷贝[root@master .ssh]# scp authorized_keys root@hadoop02:/root/.ssh/The authenticity of host &apos;hadoop02 (192.168.44.11)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:MyB1zs0E3J/fm8pC0AN8ycsgEIBNHtUqd9xS0WAyv3s.ECDSA key fingerprint is MD5:88:48:3a:ba:3e:14:a7:d7:86:f6:51:74:00:10:f9:00.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;hadoop02,192.168.44.11&apos; (ECDSA) to the list of known hosts.root@hadoop02&apos;s password: authorized_keys 100% 395 306.2KB/s 00:00 #登录slave1主机[root@slave1 ~]# cd .ssh/[root@slave1 .ssh]# lsauthorized_keys id_rsa id_rsa.pub[root@slave1 .ssh]# cat id_rsa.pub &gt;&gt; authorized_keys #使用cat追加方式 重复上步操作,将slave1的authorized_keys文件传到slave2中并将slave2中的密钥追加到该文件中.最后将slave2的authorized_keys文件传到master与slave1中 1234567#登录slave2主机，将ssh密钥加入authorized_keys文件中[root@slave2 .ssh]# cat id_rsa.pub &gt;&gt; authorized_keys #将最后生成的authorized_keys文件分别拷贝到master,slave1[root@slave2 .ssh]# scp authorized_keys root@master:/root/.ssh/[root@slave2 .ssh]# scp authorized_keys root@slave1:/root/.ssh/ 最后免密登录 2.3 修改hosts文件修改master主机hosts文件vi /etc/hosts 并添加: 123169.254.110.100 master169.254.110.101 slave1169.254.110.102 slave2 并且同步到其他主机上去 2.4 JDK安装这里不多阐述 用WinSCP传到虚拟机中然后解压并且配置环境变量 2.5 Hadoop环境配置2.5.1 上传并且解压hadoop2.8.5 hadoop-env.sh 12# 指定JDK的安装位置export JAVA_HOME=/usr/java/jdk1.8.0_201/ core-site.xml 123456789101112&lt;configuration&gt; &lt;property&gt; &lt;!--指定 namenode 的 hdfs 协议文件系统的通信地址--&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!--指定 hadoop 集群存储临时文件的目录--&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml 12345678910&lt;property&gt; &lt;!--namenode 节点数据（即元数据）的存放位置，可以指定多个目录实现容错，多个目录用逗号分隔--&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/namenode/data&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;!--datanode 节点数据（即数据块）的存放位置--&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/datanode/data&lt;/value&gt;&lt;/property&gt; yarn-site.xml 123456789101112&lt;configuration&gt; &lt;property&gt; &lt;!--配置 NodeManager 上运行的附属服务。需要配置成 mapreduce_shuffle 后才可以在 Yarn 上运行 MapReduce 程序。--&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!--resourcemanager 的主机名--&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop001&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; slaves 123masterslave1slave2 2.5.2 分发程序将 Hadoop 安装包分发到其他两台服务器，分发后建议在这两台服务器上也配置一下 Hadoop 的环境变量。 1234# 将安装包分发到hadoop002scp -r /usr/home/hadoop-2.8.5-cdh5.15.2/ root@slave1:/usr/home/# 将安装包分发到hadoop003scp -r /usr/home/hadoop-2.8.5-cdh5.15.2/ root@slave2:/usr/home/ 2.6 初始化在 master 上执行 namenode 初始化命令： 1hdfs namenode -format 2.7 启动集群在master主机中进入${HADOOP_HOME}/sbin 目录下，启动 Hadoop 1234# 启动dfs服务start-dfs.sh# 启动yarn服务start-yarn.sh 3.7 查看集群在每台服务器上使用 jps 命令查看服务进程，或直接进入 Web-UI 界面进行查看，端口为 50070。 4 提交服务到集群提交作业到集群的方式和单机环境完全一致，这里以提交 Hadoop 内置的计算 Pi 的示例程序为例，在任何一个节点上执行都可以，命令如下： 1hadoop jar /usr/app/hadoop-2.6.0-cdh5.15.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.15.2.jar pi 3 3]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[THOUGHT]]></title>
    <url>%2F2019%2F12%2F13%2FTHOUGHT%2F</url>
    <content type="text"><![CDATA[不知不觉已经很久没有打开过自己的博客去更新自己的博客,很多时候自己其实也在学习新的技术新的东西,但是就是没有心思去记录下来去写博客. 说到底还是自己太懒了. 在这学期中自己制定过一个目标—101计划,也从国庆收假后慢慢被自己遗忘了.可能真的是自己懒得去更新自己的博客,懒得去整理知识点.这可能也是我和我姐之间的差距吧.优秀的人无论何时都会想起完成自己的事.而我的事呢对于我最重要可能就是打游戏吧.哈哈 不知不觉已经快结束大三上的学习.快要到是考研还是本科毕业就工作的分岔路口了.我姐也给我打过电话,总而来说就是劝我考研希望我通过读研出身社会后能够更好的找工作,能够找更好的工作.我也理解她也能理解我的父母,他们都是想让我以后过的很好.但是自己呢,我对我自己的感觉就是属于那种喜欢贪玩,集中不了注意力,我不想拿最近失恋作为借口,因为在谈恋爱的时候我也是这种.我容易随着别人的脚步,我没有自己的主见.我也不知道自己以后该怎么办. 鸡汤我也喝过不少,但是付出的行动永远最少.就这样吧]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot整合Thymeleaf]]></title>
    <url>%2F2019%2F09%2F03%2FSpringboot%E6%95%B4%E5%90%88Thymeleaf%2F</url>
    <content type="text"><![CDATA[thymeleaf的介绍Thymeleaf 介绍Thymeleaf 是一款用于渲染 XML/XHTML/HTML5 内容的模板引擎。类似 JSP，Velocity，FreeMaker 等，它也可以轻易的与 Spring MVC 等 Web 框架进行集成作为 Web 应用的模板引擎。与其它模板引擎相比，Thymeleaf 最大的特点是能够直接在浏览器中打开并正确显示模板页面，而不需要启动整个 Web 应用。 好了，你们说了我们已经习惯使用了什么 Velocity,FreMaker，beetle之类的模版，那么到底好在哪里呢？ 比一比吧 Thymeleaf 是与众不同的，因为它使用了自然的模板技术。这意味着 Thymeleaf 的模板语法并不会破坏文档的结构，模板依旧是有效的XML文档。模板还可以用作工作原型，Thymeleaf 会在运行期替换掉静态值。Velocity 与 FreeMarke r则是连续的文本处理器。 下面的代码示例分别使用 Velocity、FreeMarker 与 Thymeleaf 打印出一条消息： 123Velocity: &lt;p&gt;$message&lt;/p&gt;FreeMarker: &lt;p&gt;$&#123;message&#125;&lt;/p&gt;Thymeleaf: &lt;p th:text=&quot;$&#123;message&#125;&quot;&gt;Hello World!&lt;/p&gt; 注意，由于 Thymeleaf 使用了 XML DOM 解析器，因此它并不适合于处理大规模的 XML 文件。 添加Jar包12345&lt;!-- thymelaef模板 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; 添加配置文件123456789101112#Thymeleaf配置#开发时关闭缓存,不然没法看到实时页面spring.thymeleaf.cache=falsespring.thymeleaf.check-template=true# 模板模式设置，默认为HTML5spring.thymeleaf.mode=HTML5spring.thymeleaf.check-template-location=truespring.thymeleaf.encoding=UTF-8spring.thymeleaf.prefix=classpath:/templates/spring.thymeleaf.servlet.content-type=text/htmlspring.thymeleaf.suffix=.html 模板中引入thymeleaf1&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; thymeleaf部分语法URLURL 在 Web 应用模板中占据着十分重要的地位，需要特别注意的是 Thymeleaf 对于 URL 的处理是通过语法 @{…} 来处理的。Thymeleaf 支持绝对路径 URL： 1&lt;a th:href=&quot;@&#123;http://www.thymeleaf.org&#125;&quot;&gt;Thymeleaf&lt;/a&gt; 条件求值 1&lt;a th:href=&quot;@&#123;/login&#125;&quot; th:unless=$&#123;session.user != null&#125;&gt;Login&lt;/a&gt; for循环 12345&lt;tr th:each=&quot;prod : $&#123;prods&#125;&quot;&gt; &lt;td th:text=&quot;$&#123;prod.name&#125;&quot;&gt;Onions&lt;/td&gt; &lt;td th:text=&quot;$&#123;prod.price&#125;&quot;&gt;2.41&lt;/td&gt; &lt;td th:text=&quot;$&#123;prod.inStock&#125;? #&#123;true&#125; : #&#123;false&#125;&quot;&gt;yes&lt;/td&gt;&lt;/tr&gt; thymeleaf中文文档Thymeleaf中文文档]]></content>
      <categories>
        <category>study</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Thymeleaf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot整合Jpa]]></title>
    <url>%2F2019%2F09%2F01%2FSpringboot%E6%95%B4%E5%90%88Jpa%2F</url>
    <content type="text"><![CDATA[添加jar包12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置文件12345678spring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.jpa.properties.hibernate.hbm2ddl.auto=updatespring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5InnoDBDialectspring.jpa.show-sql= true spring.jpa.properties.hibernate.hbm2ddl.auto这个参数的作用在于:自动创建,更新,验证数据库表的结构有以下是四个值: 1 create： 每次加载 hibernate 时都会删除上一次的生成的表，然后根据你的 model 类再重新来生成新表，哪怕两次没有任何改变也要这样执行，这就是导致数据库表数据丢失的一个重要原因。 2 create-drop ：每次加载 hibernate 时根据 model 类生成表，但是 sessionFactory 一关闭,表就自动删除。 3 update：最常用的属性，第一次加载 hibernate 时根据 model 类会自动建立起表的结构（前提是先建立好数据库），以后加载 hibernate 时根据 model 类自动更新表结构，即使表结构改变了但表中的行仍然存在不会删除以前的行。要注意的是当部署到服务器后，表结构是不会被马上建立起来的，是要等 应用第一次运行起来后才会。 4 validate ：每次加载 hibernate 时，验证创建数据库表结构，只会和数据库中的表进行比较，不会创建新表，但是会插入新值。 dialect主要是指定生成表名的存储引擎为InnoDBD show-sql是否打印出自动生成的SQL,方便调试的时候查看 添加实体类与数据表进行映射,并且配置好映射关系 12345678910111213141516171819202122232425@Entity@Data@AllArgsConstructor@NoArgsConstructorpublic class User implements Serializable &#123; private static final long serialVersionUID = 1L; @Id //设置主键 @GeneratedValue //id自增 private Long id; @Column(nullable = false,unique = true) //用户名不为空且唯一 private String userName; @Column(nullable = false) private String passWord; @Column(nullable = false) private String email; @Column(nullable = false) private String nickName; @Column(nullable = false) private String regTime;&#125; 设置DAO层dao 只要继承 JpaRepository 类就可以，几乎可以不用写方法，还有一个特别有尿性的功能非常赞，就是可以根据方法名来自动的生成 SQL，比如findByUserName 会自动生成一个以 userName 为参数的查询方法，比如 findAlll 自动会查询表里面的所有数据，比如自动分页等等。。 123456789@Repositorypublic interface UserRepository extends JpaRepository&lt;User,Long&gt; &#123; User findByUserName(String userName); User findByUserNameAndPassWord(String userName,String password); User findByUserNameOrEmail(String userName,String Email);&#125; 添加Service层UserService.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public interface UserService &#123; /** * * 功能描述: 添加用户 * * @param: user * @return: User * @auther: zy * @date: 2019/9/1 15:05 */ User saveUser(User user); /** * * 功能描述: 删除用户 * * @param: id * @return: void * @auther: zy * @date: 2019/9/1 15:06 */ void removeUser(Long id); /** * * 功能描述: 更新用户信息 * * @param: user * @return: User * @auther: zy * @date: 2019/9/1 15:06 */ User updateUser(User user); /** * * 功能描述: 通过id得到用户 * * @param: id * @return: User * @auther: zy * @date: 2019/9/1 15:06 */ User getUserByNameAndPassword(String userName,String passWord); /** * * 功能描述: 得到所有用户信息 * * @param: null * @return: List&lt;User&gt; * @auther: zy * @date: 2019/9/1 15:07 */ List&lt;User&gt; getAllUsers(); UserServiceImpl.java 1234567891011121314151617181920212223242526272829303132@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired UserRepository userRepository; @Override public User saveUser(User user) &#123; return userRepository.save(user); &#125; @Override public void removeUser(Long id) &#123; userRepository.deleteById(id); &#125; @Override public User updateUser(User user) &#123; return userRepository.save(user); &#125; @Override public User getUserByNameAndPassword(String userName, String passWord) &#123; return userRepository.findByUserNameAndPassWord(userName,passWord); &#125; @Override public List&lt;User&gt; getAllUsers() &#123; return userRepository.findAll(); &#125;&#125; 控制层(Controller)123456789101112131415161718192021@RestControllerpublic class HelloController &#123; @Autowired UserService userService; @GetMapping(&quot;/users&quot;) public User getUser()&#123; // 获取当前时间 Date date = new Date(); DateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); String time = dateFormat.format(date); User user = new User(1L,&quot;zzy001&quot;,&quot;f695112338&quot;,&quot;zyf695112338@qq.com&quot;,&quot;金毛玲&quot;,time); userService.saveUser(user); return user; &#125;&#125; Demo结果 demo]]></content>
      <categories>
        <category>study</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>JPA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis--jdbcType报错]]></title>
    <url>%2F2019%2F08%2F12%2FBuilderException-%20Error%20resolving%20JdbcType%2F</url>
    <content type="text"><![CDATA[问题启动tomcat的时候报错 12345678910111213141516171819` Caused by: org.apache.ibatis.builder.BuilderException: Error parsing Mapper XML. Cause: org.apache.ibatis.builder.BuilderException: Error resolving JdbcType. Cause: java.lang.IllegalArgumentException: No enum constant org.apache.ibatis.type.JdbcType.DATATIME at org.apache.ibatis.builder.xml.XMLMapperBuilder.configurationElement(XMLMapperBuilder.java:120) at org.apache.ibatis.builder.xml.XMLMapperBuilder.parse(XMLMapperBuilder.java:92) at org.mybatis.spring.SqlSessionFactoryBean.buildSqlSessionFactory(SqlSessionFactoryBean.java:521) ... 84 moreCaused by: org.apache.ibatis.builder.BuilderException: Error resolving JdbcType. Cause: java.lang.IllegalArgumentException: No enum constant org.apache.ibatis.type.JdbcType.DATATIME at org.apache.ibatis.builder.BaseBuilder.resolveJdbcType(BaseBuilder.java:73) at org.apache.ibatis.builder.xml.XMLMapperBuilder.buildResultMappingFromContext(XMLMapperBuilder.java:382) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElement(XMLMapperBuilder.java:280) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElement(XMLMapperBuilder.java:252) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElements(XMLMapperBuilder.java:244) at org.apache.ibatis.builder.xml.XMLMapperBuilder.configurationElement(XMLMapperBuilder.java:116) ... 86 moreCaused by: java.lang.IllegalArgumentException: No enum constant org.apache.ibatis.type.JdbcType.DATATIME at java.lang.Enum.valueOf(Enum.java:238) at org.apache.ibatis.type.JdbcType.valueOf(JdbcType.java:25) at org.apache.ibatis.builder.BaseBuilder.resolveJdbcType(BaseBuilder.java:71) ... 91 more` 原因看报错的原因,是因为我在resultmap中jdbcType写了datatime,而在mybatis中是这个数据类型的 解决办法修改resultmap中的jdbcType即可 Tip我去网上查看了源码,发现mybatis的jdbcType是一个枚举类,有以下类型: 12345678910111213141516171819202122232425262728293031323334353637383940public enum JdbcType &#123; ARRAY(2003), BIT(-7), TINYINT(-6), SMALLINT(5), INTEGER(4), BIGINT(-5), FLOAT(6), REAL(7), DOUBLE(8), NUMERIC(2), DECIMAL(3), CHAR(1), VARCHAR(12), LONGVARCHAR(-1), DATE(91), TIME(92), TIMESTAMP(93), BINARY(-2), VARBINARY(-3), LONGVARBINARY(-4), NULL(0), OTHER(1111), BLOB(2004), CLOB(2005), BOOLEAN(16), CURSOR(-10), UNDEFINED(-2147482648), NVARCHAR(-9), NCHAR(-15), NCLOB(2011), STRUCT(2002), JAVA_OBJECT(2000), DISTINCT(2001), REF(2006), DATALINK(70), ROWID(-8), LONGNVARCHAR(-16), SQLXML(2009), DATETIMEOFFSET(-155); 总结希望以后自己能越过这个坎,多长记性.]]></content>
      <categories>
        <category>study</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea--target不同步问题]]></title>
    <url>%2F2019%2F08%2F09%2F%E5%85%B3%E4%BA%8Eidea%E4%B8%ADtarget%E4%B8%8D%E5%90%8C%E6%AD%A5%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题所在ssm小项目中,加入了新的css文件和js文件,然后重启项目,发现并没有效果.然鹅在页面中也及时的引用了相关的css和js文件. 分析原因我使用的idea编译器,发现target文件中并没有相关的css和js文件,导致我在页面中引入了等同于没有引用,所以导致页面没有相关的效果. 解决办法先清理项目中的target目录,然后再rebuild项目即可 12//清理target目录mvn clean package 然后rebuild项目(快捷键Ctrl+Shift+F9) 解决问题ok拉!!]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记:Mybatis-PageHelper]]></title>
    <url>%2F2019%2F07%2F17%2FMybatis%E4%B9%8BPagehelper%2F</url>
    <content type="text"><![CDATA[前言Mybatis为我们提供了非常优秀的分页插件PageHelper该插件支持任何复杂的单表或者是多表. PageHelper实现了通用的分页查询,支持的数据有mysql,Oracle,DB2,PostgreSQL等该插件托管于github: https://github.com/pagehelper/Mybatis-PageHelper如何使用PageHelper导入依赖- 使用maven导入12345678910&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.jsqlparser&lt;/groupId&gt; &lt;artifactId&gt;jsqlparser&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt; 导入jar包1). 你可以从下面的地址中下载最新版本的 jar 包 https://oss.sonatype.org/content/repositories/releases/com/github/pagehelper/pagehelper/ http://repo1.maven.org/maven2/com/github/pagehelper/pagehelper/ 2). 由于使用了sql 解析工具，你还需要下载 jsqlparser.jar： http://repo1.maven.org/maven2/com/github/jsqlparser/jsqlparser/0.9.5/配置拦截器插件特别注意，新版拦截器是 com.github.pagehelper.PageInterceptor com.github.pagehelper.PageHelper 现在是一个特殊的 dialect 实现类，是分页插件的默认实现类，提供了和以前相同的用法。 在Mybatis配置xml中配置拦截器插件123456&lt;plugins&gt; &lt;plugin interceptor=&quot;com.github.pagehelper.PageInterceptor&quot;&gt; &lt;!--分页参数合理化 --&gt; &lt;property name=&quot;reasonable&quot; value=&quot;true&quot;/&gt; &lt;/plugin&gt; &lt;/plugins&gt; 在Spring配置文件中配置拦截器插件使用 spring 的属性配置方式，可以使用 plugins 属性像下面这样配置： 123456789101112131415&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!-- 注意其他配置 --&gt; &lt;property name=&quot;plugins&quot;&gt; &lt;array&gt; &lt;bean class=&quot;com.github.pagehelper.PageInterceptor&quot;&gt; &lt;property name=&quot;properties&quot;&gt; &lt;!--使用下面的方式配置参数，一行配置一个 --&gt; &lt;value&gt; params=value1 &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt;&lt;/bean&gt; 确确实实去配置文件会让人显得很郁闷也很头疼. 所以我一般参照官方文档去配置,里面不仅有分页插件的参数介绍还有常用的配置参数,不同的场景需要配置不同的参数. 参考PageHelper官方文档 DAO层在我做的demo中,我是获取所有部门然后在使用分页插件进行物理分页. 1234public interface DepartmentMapper &#123; //获取所有部门 List&lt;Department&gt; getAll();&#125; Service层1234public interface DepartmentService &#123;//查询所有 List&lt;Department&gt; getAll();&#125; 实现相应的接口 12345678910@Servicepublic class DepartmentServiceImpl implements DepartmentService &#123; @Autowired DepartmentMapper departmentMapper; @Override public List&lt;Department&gt; getAll() &#123; return departmentMapper.getAll(); &#125;&#125; Controller层在控制器中,是跳转到部门的页面的时候将数据查询到然后使用PageHelper 1234567891011121314151617181920212223242526272829303132/** * @project : HRM * @description : 控制器-首页管理 * @author : zy */@Controller@RequestMapping(&quot;main&quot;)public class MainController &#123; @Autowired UserService userService; @Autowired DepartmentService departmentService; @Autowired EmployeeService employeeService; /** * @decription 查询所有部门信息并跳转到部门信息页面(分页查询) * @param model * @return */ @RequestMapping(&quot;toDepartmentList.html&quot;) public String toDepartmentList(@RequestParam(value = &quot;pn&quot;, defaultValue = &quot;1&quot;) Integer pn, Model model)&#123; //pn为当前页码,每页的大小为5 PageHelper.startPage(pn,5); List&lt;Department&gt; departmentList = departmentService.getAll(); //导航栏最多为5页 PageInfo pageInfo = new PageInfo(departmentList,5); model.addAttribute(&quot;pageInfo&quot;,pageInfo); return &quot;Dep/DepartmentList&quot;;&#125;&#125; 使用PageHelper的静态方法:PageHelper.startPage(currentPage,PageSize)(currentPage是指的当前页数PageSize是指的是每页的大小) 使用PageInfo对象在使用PageHelper.start后,我们可以使用PageInfo进行封装,可以从PageInfo中获得更多的信息,比如:当前页码,最后页码等等(详情5.3) 这里使用进行了分页封装,departmentList实际上是一个代理对象. 1PageInfo pageInfo = new PageInfo(departmentList,5); PageInfo的属性参数,成员变量1234567891011121314151617181920212223242526272829303132333435363738394041//当前页private int pageNum; //每页的数量private int pageSize; //当前页的数量private int size;//总记录数private long total; //总页数private int pages; //结果集(每页显示的数据)private List&lt;T&gt; list; //第一页private int firstPage; //前一页private int prePage; //是否为第一页private boolean isFirstPage = false; //是否为最后一页private boolean isLastPage = false; //是否有前一页private boolean hasPreviousPage = false; //是否有下一页private boolean hasNextPage = false; //导航页码数private int navigatePages; //所有导航页号private int[] navigatepageNums; View层(JSP)这里使用了test12345678910111213141516171819202122232425262728293031323334```&lt;div class=&quot;&quot; style=&quot;position: fixed;left: 500px;top: 490px;&quot;&gt; 当前 $&#123;pageInfo.pageNum&#125; 页,总 $&#123;pageInfo.pages&#125; 页,总 $&#123;pageInfo.total&#125; 条记录 &lt;/div&gt; &lt;div class=&quot;&quot; style=&quot;position: fixed;right: 500px;top: 460px;&quot;&gt; &lt;nav aria-label=&quot;Page navigation&quot;&gt; &lt;ul class=&quot;pagination&quot;&gt; &lt;li&gt;&lt;a href=&quot;/main/toDepartmentList.html?pn=1&quot;&gt;首页&lt;/a&gt;&lt;/li&gt; &lt;c:if test=&quot;$&#123;pageInfo.hasPreviousPage&#125;&quot;&gt; &lt;li&gt; &lt;a href=&quot;/main/toDepartmentList.html?pn=$&#123;pageInfo.pageNum-1&#125;&quot; aria-label=&quot;Previous&quot;&gt; &lt;span aria-hidden=&quot;true&quot;&gt;&amp;laquo;&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &lt;/c:if&gt; &lt;c:forEach items=&quot;$&#123;pageInfo.navigatepageNums&#125;&quot; var=&quot;pagenum&quot;&gt; &lt;c:if test=&quot;$&#123;pagenum == pageInfo.pageNum&#125;&quot;&gt; &lt;li class=&quot;active&quot;&gt;&lt;a href=&quot;/main/toDepartmentList.html?pn=$&#123;pagenum&#125;&quot;&gt;$&#123;pagenum&#125;&lt;/a&gt;&lt;/li&gt; &lt;/c:if&gt; &lt;c:if test=&quot;$&#123;pagenum != pageInfo.pageNum&#125;&quot;&gt; &lt;li&gt;&lt;a href=&quot;/main/toDepartmentList.html?pn=$&#123;pagenum&#125;&quot;&gt;$&#123;pagenum&#125;&lt;/a&gt;&lt;/li&gt; &lt;/c:if&gt; &lt;/c:forEach&gt; &lt;c:if test=&quot;$&#123;pageInfo.hasNextPage&#125;&quot;&gt; &lt;li&gt; &lt;a href=&quot;/main/toDepartmentList.html?pn=$&#123;pageInfo.pageNum+1&#125;&quot; aria-label=&quot;Next&quot;&gt; &lt;span aria-hidden=&quot;true&quot;&gt;&amp;raquo;&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/main/toDepartmentList.html?pn=$&#123;pageInfo.pages&#125;&quot;&gt;末页&lt;/a&gt;&lt;/li&gt; &lt;/c:if&gt; &lt;/ul&gt; &lt;/nav&gt; &lt;/div&gt; demo截图 ZOuKRP.jpg 结尾第一次写笔记,感觉自己还是做的很不够,思路不够清晰,写的不太好也写的太慢… 希望自己能够在以后写的越来越好. 可爱的猫猫]]></content>
      <categories>
        <category>study</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客备份]]></title>
    <url>%2F2019%2F07%2F17%2FHexo%E5%8D%9A%E5%AE%A2%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[关于hexo博客备份使用 Hexo 在 GitHub Pages 搭建博客时，博客作为一个单独的 GitHub 仓库存在，但是这个仓库只有生成的静态网页文件，并没有 Hexo 的源文件。这样一来换电脑或者重装系统后，再想找回源文件就比较麻烦了，这里推荐一种比较完美的方法解决备份问题。 备份 创建仓库 WincerChan.github.io，如果同名仓库之前已经创建，请将之前的仓库改名新建的仓库必须是 Username.github.io（如果你是将 Hexo 博客部署到了自己的服务器，那么仓库名可以随意设置，我这里就是随意设置的仓库） 创建两个分支：master 和 hexo； 设置 hexo 为默认分支 将刚刚创建的新仓库 clone 至本地，将之前的 hexo 文件夹中的 _config.yml、themes/、source/、scaffolds/、package.json 和 .gitignore 复制至 WincerChan.github.io 文件夹 将 themes/next/（我用的是 NexT 主题）中的 .git/ 删除，否则无法将主题文件夹 push（也可以将主题文件夹使用子模块的方式添加到该仓库) 在 WincerChan.github.io 文件夹执行 npm install 和 npm install hexo-deployer-git（这里可以看一看分支是不是显示为 hexo） 执行 git add、git commit -m “”、git push origin hexo 来提交 hexo 网站源文件； 执行 hexo g -d 生成静态网页部署至 Github 上 修改 依次执行 git add、git commit -m “” 和 git push origin hexo 来提交 hexo 网站源文件 执行 hexo g -d 生成静态网页部署至 Github 上 恢复 安装 git 安装Nodejs和npm 使用 git clone git#github.com:WincerChan/WincerChan.github.io.git 将仓库拷贝至本地 在文件夹内执行以下命令 npm install hexo-cli -g、npm install、npm install hexo-deployer-git]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git basic command]]></title>
    <url>%2F2019%2F07%2F17%2Fgit-basic-command%2F</url>
    <content type="text"><![CDATA[###Git 基本命令 git init (命令把这个目录变成Git可以管理的仓库)12$ git initInitialized empty Git repository in /Users/michael/learngit/.git/ git add (将文件添加到仓库)1git add readme.txt git commit (将文件提交到仓库)1234$ git commit -m &quot;wrote a readme file&quot;[master (root-commit) eaadf4e] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt (这里git commit -m “这里是添加本次提交的说明”git add 是可以添加多个文件,而git commit是可以一次提交多个的) git status (查看当前仓库的状态)123456789$ git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: readme.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) (这里表示readme.txt是已经修改了,但是还没有提交修改) git diff (查看不同(difference))123456789$ git diff readme.txt diff --git a/readme.txt b/readme.txtindex 46d49bf..9247db6 100644--- a/readme.txt+++ b/readme.txt@@ -1,2 +1,2 @@-Git is a version control system.+Git is a distributed version control system. Git is free software. git log (命令显示从最近到最远的提交日志)123456789101112131415161718$ git logcommit 1094adb7b9b3807259d8cb349e7df1d4d6477073 (HEAD -&gt; master)Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:06:15 2018 +0800 append GPLcommit e475afc93c209a690c39c13a46716e8fa000c366Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 21:03:36 2018 +0800 add distributedcommit eaadf4e385e865d25c48e7ca9c8395c3f7dfaef0Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Fri May 18 20:59:18 2018 +0800 wrote a readme file (如果嫌输出信息太多，看得眼花缭乱的，可以试试加上–pretty=oneline参数：) 1234$ git log --pretty=oneline1094adb7b9b3807259d8cb349e7df1d4d6477073 (HEAD -&gt; master) append GPLe475afc93c209a690c39c13a46716e8fa000c366 add distributedeaadf4e385e865d25c48e7ca9c8395c3f7dfaef0 wrote a readme file]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F06%2F25%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
